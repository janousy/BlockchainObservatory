{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7884c44f-3c62-485e-862b-e3cffeab9c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importstatements\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as F     \n",
    "\n",
    "from pyspark.sql import types \n",
    "from pyspark.sql.types import StructField, StringType, LongType, DoubleType, BooleanType, StructType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68f3779c-1c4d-4ab2-a9ed-71d2b10e17ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config for our sparksession\n",
    "config = pyspark.SparkConf().setAll([\n",
    "    ('spark.executor.memory', '16g'), \n",
    "    ('spark.executor.cores', '4'), \n",
    "    ('spark.cores.max', '8'),\n",
    "    ('spark.driver.memory','2g'),\n",
    "    ('spark.executor.instances', '1'),\n",
    "    ('spark.dynamicAllocation.enabled', 'true'),\n",
    "    ('spark.dynamicAllocation.shuffleTracking.enabled', 'true'),\n",
    "    ('spark.dynamicAllocation.executorIdleTimeout', '60s'),\n",
    "    ('spark.dynamicAllocation.minExecutors', '2'),\n",
    "    ('spark.dynamicAllocation.maxExecutors', '2'),\n",
    "    ('spark.dynamicAllocation.initialExecutors', '1'),\n",
    "    ('spark.dynamicAllocation.executorAllocationRatio', '1'),\n",
    "    ('spark.worker.cleanup.enabled', 'true'),\n",
    "    ('spark.worker.cleanup.interval', '60'),\n",
    "    ('spark.shuffle.service.db.enabled', 'true'),\n",
    "    ('spark.worker.cleanup.appDataTtl', '60rite'),\n",
    "    ('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector:10.0.2')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a5b9de-2b74-4777-99f7-8ee015000878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/13 16:30:42 WARN Utils: Your hostname, algorand-druid-and-spark resolves to a loopback address: 127.0.0.1; using 172.23.149.212 instead (on interface ens3)\n",
      "22/07/13 16:30:42 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-eedce58f-4095-431d-8338-e4dec9f4bb31;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector;10.0.2 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.5.1 in central\n",
      "\t[4.5.1] org.mongodb#mongodb-driver-sync;[4.5.0,4.5.99)\n",
      "\tfound org.mongodb#bson;4.5.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.5.1 in central\n",
      ":: resolution report :: resolve 3353ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.5.1 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.5.1 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.5.1 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector;10.0.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   1   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-eedce58f-4095-431d-8338-e4dec9f4bb31\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/5ms)\n",
      "22/07/13 16:30:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/07/13 16:30:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/07/13 16:30:52 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/07/13 16:30:52 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "22/07/13 16:30:52 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "22/07/13 16:30:52 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "22/07/13 16:30:52 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "22/07/13 16:30:54 WARN Utils: spark.dynamicAllocation.initialExecutors less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n",
      "22/07/13 16:30:54 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n",
      "22/07/13 16:30:54 WARN ExecutorAllocationManager: Dynamic allocation without a shuffle service is an experimental feature.\n"
     ]
    }
   ],
   "source": [
    "#create sparksession\n",
    "#when copying change appName\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(conf=config) \\\n",
    "    .appName(\"7_TransactionUseCases\") \\\n",
    "    .master(\"spark://172.23.149.212:7077\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599343d0-8849-4704-a45e-c1af2fea3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a schema so all data quality is ensured\n",
    "schema = StructType([ \\\n",
    "    StructField(\"_id\", StringType(), True), \\\n",
    "    StructField(\"asset\", LongType(), True), \\\n",
    "    StructField(\"extra\", StringType(), True), \\\n",
    "    StructField(\"intra\", LongType(), True), \\\n",
    "    StructField(\"round\", LongType(), True), \\\n",
    "    StructField(\"rr\", LongType(), True), \\\n",
    "    StructField(\"sig\", StringType(), True), \\\n",
    "    StructField(\"txid\", StringType(), True), \\\n",
    "    StructField(\"txn_aamt\", LongType(), True), \\\n",
    "    StructField(\"txn_aclose\", StringType(), True), \\\n",
    "    StructField(\"txn_afrz\", BooleanType(), True), \\\n",
    "    StructField(\"txn_amt\", LongType(), True), \\\n",
    "    StructField(\"txn_apaa\", StringType(), True), \\\n",
    "    StructField(\"txn_apan\", LongType(), True), \\\n",
    "    StructField(\"txn_apap\", StringType(), True), \\\n",
    "    StructField(\"txn_apar\", StringType(), True), \\\n",
    "    StructField(\"txn_apas\", StringType(), True), \\\n",
    "    StructField(\"txn_apat\", StringType(), True), \\\n",
    "    StructField(\"txn_apep\", StringType(), True), \\\n",
    "    StructField(\"txn_apfa\", StringType(), True), \\\n",
    "    StructField(\"txn_apgs\", StringType(), True), \\\n",
    "    StructField(\"txn_apid\", LongType(), True), \\\n",
    "    StructField(\"txn_apls\", StringType(), True), \\\n",
    "    StructField(\"txn_apsu\", StringType(), True), \\\n",
    "    StructField(\"txn_arcv\", StringType(), True), \\\n",
    "    StructField(\"txn_asnd\", StringType(), True), \\\n",
    "    StructField(\"txn_caid\", LongType(), True), \\\n",
    "    StructField(\"txn_close\", StringType(), True), \\\n",
    "    StructField(\"txn_fadd\", StringType(), True), \\\n",
    "    StructField(\"txn_faid\", LongType(), True), \\\n",
    "    StructField(\"txn_fee\", LongType(), True), \\\n",
    "    StructField(\"txn_fv\", LongType(), True), \\\n",
    "    StructField(\"txn_gen\", StringType(), True), \\\n",
    "    StructField(\"txn_gh\", StringType(), True), \\\n",
    "    StructField(\"txn_grp\", StringType(), True), \\\n",
    "    StructField(\"txn_lsig\", StringType(), True), \\\n",
    "    StructField(\"txn_lv\", LongType(), True), \\\n",
    "    StructField(\"txn_lx\", StringType(), True), \\\n",
    "    StructField(\"txn_msig\", StringType(), True), \\\n",
    "    StructField(\"txn_nonpart\", BooleanType(), True), \\\n",
    "    StructField(\"txn_note\", StringType(), True), \\\n",
    "    StructField(\"txn_rcv\", StringType(), True), \\\n",
    "    StructField(\"txn_rekey\", StringType(), True), \\\n",
    "    StructField(\"txn_selkey\", StringType(), True), \\\n",
    "    StructField(\"txn_sig\", StringType(), True), \\\n",
    "    StructField(\"txn_snd\", StringType(), True), \\\n",
    "    StructField(\"txn_type\", StringType(), True), \\\n",
    "    StructField(\"txn_votefst\", LongType(), True), \\\n",
    "    StructField(\"txn_votekd\", LongType(), True), \\\n",
    "    StructField(\"txn_votekey\", StringType(), True), \\\n",
    "    StructField(\"txn_votelst\", LongType(), True), \\\n",
    "    StructField(\"txn_xaid\", LongType(), True), \\\n",
    "    StructField(\"typeenum\", IntegerType(), True) \\\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6320f296-3b81-4103-a4e1-d9803e0a20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account table to determine which accounts have received rewards\n",
    "dfTx = spark.read.format(\"mongodb\") \\\n",
    "    .option('spark.mongodb.connection.uri', 'mongodb://172.23.149.212:27017') \\\n",
    "    .option('spark.mongodb.database', 'algorand') \\\n",
    "    .option('spark.mongodb.collection', 'txn') \\\n",
    "    .option('park.mongodb.read.readPreference.name', 'primaryPreferred') \\\n",
    "    .option('spark.mongodb.change.stream.publish.full.document.only','true') \\\n",
    "    .option(\"forceDeleteTempCheckpointLocation\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47fe03dd-360c-464b-aab6-f5eefb883f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all unnecessary tables\n",
    "dfTx = dfTx.select(\"typeenum\", \"round\", \"txn_snd\", \"txn_type\", \"txn_apid\", \"txn_apan\", \"txn_apas\", \"txn_apap\", \"txid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5344e3d0-2592-480e-a866-fe839426b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use case based grouping\n",
    "#1-> payment transaction\n",
    "#2-> Keyreg transaction\n",
    "#3-> asset configuration\n",
    "#4-> asset transfer\n",
    "#5-> asset freeze\n",
    "#6-> application transactions\n",
    "dfTx = dfTx.withColumn(\"usecase\", F.when(F.col('typeenum')== 1, \"payment\")\n",
    "                       .when(F.col('typeenum')== 2, \"keyreg\")\n",
    "                       .when(F.col('typeenum')== 3, \"assetconfig\")\n",
    "                       .when(F.col('typeenum')== 4, \"assettransfer\")\n",
    "                       .when(F.col('typeenum')== 5, \"assetfreeze\")\n",
    "                       .when(F.col('typeenum')== 6, \"application\"))\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db367e1a-dc1a-4909-bb77-8086664e66a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxGroupUseCases = dfTx.groupBy(\"usecase\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ddcafe1-3577-4642-9f28-edb728be4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newest round has to be calculated\n",
    "newestRound = dfTx.agg(F.max(\"round\")).collect()[0][0]\n",
    "dfTxGroupUseCasesGold = dfTxGroupUseCases.withColumn(\"CreationRound\", F.lit(newestRound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65923a36-332f-491f-b3dc-02a3dfa86223",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTxGroupUseCasesGold.write.format(\"mongodb\") \\\n",
    "\t.option('spark.mongodb.connection.uri', 'mongodb://172.23.149.212:27017') \\\n",
    "  \t.mode(\"append\") \\\n",
    "    .option('spark.mongodb.database', 'algorand_gold') \\\n",
    "  \t.option('spark.mongodb.collection', 'TransactionsByUseCase_7') \\\n",
    "  \t.option(\"forceDeleteTempCheckpointLocation\", \"true\") \\\n",
    "  \t.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e91c6-ffe0-435d-bd37-34a2174c1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect so a python object is created\n",
    "graph = dfTxGroupUseCases.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b55c2-66e4-4c42-a2b1-043e9c769bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert row[\"data\"] to only data\n",
    "UCnames = [row[0] for (row) in graph]\n",
    "UCvalues = [row[1] for (row) in graph]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34b147-282d-4497-8e05-b1c5383c0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(len(UCnames)):\n",
    "    plt.bar(UCnames[i], UCvalues[i], width = 0.4)\n",
    "    \n",
    "plt.title(\"Smart Contract Use Case Transactions\", loc ='center', pad = None)\n",
    "plt.savefig('/home/ubuntu/apps/figures/7_TransactionUC/TC_Use_Cases.jpg', dpi= 200)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
